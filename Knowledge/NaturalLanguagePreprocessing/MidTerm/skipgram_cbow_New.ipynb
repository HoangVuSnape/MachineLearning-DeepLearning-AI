{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip gram and CBOW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MyJGHC1BaWl"
   },
   "source": [
    "We will built the Skipgram and CBOW models from scratch, train them on a relatively small corpus, i.e, on BBC Data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vkdi2YQiz3Fc"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import operator\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Reshape, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors as nn\n",
    "from matplotlib import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Snape\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Snape\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMNFODiS2UXU",
    "outputId": "ae02bceb-305a-45d8-9428-adecb4d9a670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           category                                               text\n",
      "0              tech  tv future in the hands of viewers with home th...\n",
      "1          business  worldcom boss  left books alone  former worldc...\n",
      "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
      "3             sport  yeading face newcastle in fa cup premiership s...\n",
      "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
      "...             ...                                                ...\n",
      "1451       business  egypt to sell off state-owned bank the egyptia...\n",
      "1452           tech  spam e-mails tempt net shoppers computer users...\n",
      "1453           tech  broadband set to revolutionise tv bt is starti...\n",
      "1454           tech  can yahoo dominate next decade  yahoo has reac...\n",
      "1455       politics  lib dems target first-time buyers the liberal ...\n",
      "\n",
      "[1456 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bbc-text.csv')\n",
    "print(df)\n",
    "articles = list(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(filePath):\n",
    "    word_vectors = {}\n",
    "    i = 0\n",
    "    with open(filePath, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            i += 1\n",
    "            if i == 1:\n",
    "                continue  # Skip the header\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array([float(x) for x in parts[1:]])\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "\n",
    "def nearestWords(target_word, word_vectors, top_n=10):\n",
    "    if target_word not in word_vectors:\n",
    "        return f\"Word '{target_word}' not found in the word vectors.\"\n",
    "    \n",
    "    target_vector = word_vectors[target_word].reshape(1, -1)\n",
    "    similarities = {}\n",
    "    \n",
    "    for word, vector in word_vectors.items():\n",
    "        if word == target_word:\n",
    "            continue\n",
    "        similarity = cosine_similarity(target_vector, vector.reshape(1, -1))[0][0]\n",
    "        similarities[word] = similarity\n",
    "    \n",
    "    # Sort by similarity in descending order and get the top_n words\n",
    "    nearest_words = sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:top_n]\n",
    "    \n",
    "    return nearest_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions for cleaning text\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')  # Remove characters in this set with a space\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')           # Remove any character that is not alphanumeric or a space\n",
    "STOPWORDS = set(stopwords.words('english'))            # Set of English stopwords\n",
    "\n",
    "# Function to prepare text data\n",
    "def text_prepare(text):\n",
    "    text = text.lower()                                # Convert text to lowercase\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)      # Replace specified characters with a space\n",
    "    text = re.sub(BAD_SYMBOLS_RE, '', text)            # Remove symbols not allowed\n",
    "    token_words = word_tokenize(text)                  # Tokenize the text into words\n",
    "    filtered_words = [word for word in token_words if word not in STOPWORDS]  # Remove stopwords\n",
    "    text = ''\n",
    "    for word in filtered_words:                       \n",
    "        if word != filtered_words[len(filtered_words)-1]:  # If not the last word, add a space after the word\n",
    "            text = text + word + ' '\n",
    "        else:                                          # If it's the last word, don't add a space after it\n",
    "            text = text + word\n",
    "    return text  # Return the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUsTuWeG9_Km",
    "outputId": "82ec76f4-dc73-40b5-ed61-c84eed6b6cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 516 ms\n",
      "Wall time: 5.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for i in articles[:]:\n",
    "    sentences += i.split('.')\n",
    "\n",
    "\n",
    "corpus = [sentence for sentence in sentences if sentence.count(\" \") >= 5]\n",
    "\n",
    "# Apply text_prepare to each sentence in corpus\n",
    "corpus_cleaned = [text_prepare(sentence) for sentence in corpus]\n",
    "\n",
    "# Remove punctuation in text and fit tokenizer on entire corpus\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus_cleaned)\n",
    "\n",
    "# Convert text to sequence of integer values\n",
    "corpus_sequences = tokenizer.texts_to_sequences(corpus_cleaned)\n",
    "\n",
    "n_samples = sum(len(s) for s in corpus_sequences) # Total number of words in the corpus\n",
    "V = len(tokenizer.word_index) + 1 # Total number of unique words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tv future in the hands of viewers with home theatre systems  plasma high-definition tvs  and digital video recorders moving into the living room  the way people watch tv will be radically different in five years  time'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkpMdk0W_Tvb",
    "outputId": "3d7b2189-5295-4738-cf5f-a331cc04a8ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324119, 27442)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8H_KWQi_Vg-",
    "outputId": "d7a0d387-cdbf-413e-99c3-94c65cf1cd00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said', 1), ('mr', 2), ('would', 3), ('also', 4), ('people', 5)]\n"
     ]
    }
   ],
   "source": [
    "# Example of how word to integer mapping looks like in the tokenizer\n",
    "print(list((tokenizer.word_index.items()))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93,\n",
       " 142,\n",
       " 1075,\n",
       " 1039,\n",
       " 45,\n",
       " 968,\n",
       " 711,\n",
       " 6803,\n",
       " 1440,\n",
       " 4851,\n",
       " 110,\n",
       " 154,\n",
       " 3623,\n",
       " 1383,\n",
       " 1216,\n",
       " 1484,\n",
       " 38,\n",
       " 5,\n",
       " 930,\n",
       " 93,\n",
       " 5222,\n",
       " 342,\n",
       " 94,\n",
       " 18,\n",
       " 16]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27552\n",
      "27552\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_cleaned))\n",
    "print(len(corpus_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "49Vrpesb_X5v"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "window_size = 2\n",
    "window_size_corpus = 4\n",
    "\n",
    "# Set numpy seed for reproducible results\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9Yh1m9sn_auh"
   },
   "outputs": [],
   "source": [
    "# Assuming corpus_sequences is obtained from tokenizer.texts_to_sequences(corpus_cleaned)\n",
    "\n",
    "# Now, let's generate skipgram data using the tokenized sequences\n",
    "def generate_data_skipgram(corpus_sequences, window_size, V):\n",
    "    # Calculate the maximum length of each part of the window\n",
    "    # Initialize lists to store input words and their context words\n",
    "    all_in = []\n",
    "    all_out = []\n",
    "    \n",
    "    # Loop through each sequence of tokens in the corpus\n",
    "    for words in corpus_sequences:\n",
    "        # Get the length of the sequence\n",
    "        L = len(words)\n",
    "        \n",
    "        # Iterate over each word in the sequence\n",
    "        for index, word in enumerate(words):\n",
    "            # Calculate the start and end indices of the context window\n",
    "            p = index - window_size\n",
    "            n = index + window_size + 1\n",
    "            \n",
    "            # Iterate over each word in the context window\n",
    "            for i in range(p, n):\n",
    "                # Check if the word is not the target word and is within the sequence\n",
    "                if i != index and 0 <= i < L:\n",
    "                    # Add the target word to the input list\n",
    "                    all_in.append(word)\n",
    "                    # Add the one-hot representation of the context word to the output list\n",
    "                    all_out.append(to_categorical(words[i], V))\n",
    "\n",
    "    # Convert the lists to numpy arrays and return\n",
    "    return (np.array(all_in), np.array(all_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0dDFx_a_b9q",
    "outputId": "239052ee-cd76-44a3-90c4-d708f4bdea9f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create training data\n",
    "# Now, let's generate skipgram data\n",
    "X_skip, y_skip = generate_data_skipgram(corpus_sequences, window_size, V)\n",
    "X_skip.shape, y_skip.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 147  147  298  298  298 2035 2035 2035 2035  701  701  701  701]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_skip[0:13])\n",
    "print(y_skip[0:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFII7Bz5_dXp",
    "outputId": "1e22e91c-58ba-4ac2-e83b-a798e6507e80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Snape\\anaconda3\\envs\\torch\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: total: 297 ms\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create skipgram architecture\n",
    "\n",
    "dim = 300\n",
    "skipgram_models = []\n",
    "\n",
    "# Initialize a Keras Sequential model\n",
    "skipgram = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "skipgram.add(Embedding(input_dim=V,\n",
    "                        output_dim=dim,\n",
    "                        input_length=1,\n",
    "                        embeddings_initializer='glorot_uniform'))\n",
    "\n",
    "# Add a Reshape layer, which reshapes the output of the embedding layer (1,dim) to (dim,)\n",
    "skipgram.add(Reshape((dim, )))\n",
    "\n",
    "# Add a final Dense layer with the same size as in [1]\n",
    "skipgram.add(Dense(V, activation='softmax', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "# Compile the model with a suitable loss function and select an optimizer.\n",
    "# Optimizer Adagrad was used in paper\n",
    "skipgram.compile(optimizer=keras.optimizers.Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "skipgram.summary()\n",
    "print(\"\")\n",
    "skipgram_models.append(skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWouhLLB_gpb",
    "outputId": "f89aed64-39fe-4b7e-cc3c-c60bc5cd77b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 103ms/step - accuracy: 0.0131 - loss: 8.7858\n",
      "Epoch 2/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 65ms/step - accuracy: 0.0239 - loss: 7.9557\n",
      "Epoch 3/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 43ms/step - accuracy: 0.0486 - loss: 7.0382\n",
      "Epoch 4/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 71ms/step - accuracy: 0.0668 - loss: 5.9886\n",
      "Epoch 5/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 77ms/step - accuracy: 0.0711 - loss: 5.1330\n",
      "Epoch 6/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 27ms/step - accuracy: 0.0654 - loss: 4.5881\n",
      "Epoch 7/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 46ms/step - accuracy: 0.0619 - loss: 4.2933\n",
      "Epoch 8/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 82ms/step - accuracy: 0.0576 - loss: 4.1314\n",
      "Epoch 9/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 69ms/step - accuracy: 0.0570 - loss: 4.0523\n",
      "Epoch 10/10\n",
      "\u001b[1m2264/2264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 45ms/step - accuracy: 0.0566 - loss: 3.9969\n",
      "\n",
      "CPU times: total: 1h 1min 42s\n",
      "Wall time: 24min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the skipgram models\n",
    "for skipgram in skipgram_models:\n",
    "    skipgram.fit(X_skip, y_skip, batch_size=64, epochs=10, verbose=1)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cldfl4HP_jAE"
   },
   "outputs": [],
   "source": [
    "\n",
    "for skipgram in skipgram_models:\n",
    "    # Save embeddings for vectors of length 50, 150 and 300 using skipgram model\n",
    "    weights = skipgram.get_weights()\n",
    "\n",
    "    # Get the embedding matrix\n",
    "    embedding = weights[0]\n",
    "\n",
    "    # Get word embeddings for each word in the vocabulary, write to file\n",
    "    f = open(f\"vectors_skipgram_{len(embedding[0])}.txt\", \"w\")\n",
    "\n",
    "    # Create columns for the words and the values in the matrix, makes it easier to read as dataframe\n",
    "    columns = [\"word\"] + [f\"value_{i+1}\" for i in range(embedding.shape[1])]\n",
    "\n",
    "    # Start writing to the file, start with the column names\n",
    "    f.write(\" \".join(columns))\n",
    "\n",
    "    # Start a new line\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        f.write(word)\n",
    "        f.write(\" \")\n",
    "        f.write(\" \".join(map(str, list(embedding[i,:]))))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5nkl5mF_n1H",
    "outputId": "912e9445-ddc8-47b5-da78-57732bc7684c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01748095,  0.00148425, -0.01919544, ..., -0.00088694,\n",
       "        -0.01220941, -0.0135742 ],\n",
       "       [ 0.32527888, -0.12163258,  0.16216542, ..., -0.18126906,\n",
       "         0.12671961, -0.10615522],\n",
       "       [ 0.42963627,  0.21860029,  0.03769287, ...,  0.31626388,\n",
       "        -0.19132   , -0.01692916],\n",
       "       ...,\n",
       "       [-0.13268201, -0.2621697 , -0.13941467, ...,  0.3050503 ,\n",
       "        -0.06711472, -0.07819138],\n",
       "       [ 0.2811083 ,  0.11811126,  0.06614776, ..., -0.1773975 ,\n",
       "         0.20586096, -0.14225566],\n",
       "       [ 0.20672405, -0.08174837,  0.00601677, ..., -0.03199767,\n",
       "         0.42297745,  0.11940225]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MMXBpKICNld",
    "outputId": "b68d04cf-3b5f-4fb0-ac5e-7dddcd1016e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skipgram.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QM00BJo8CZgf",
    "outputId": "6789022e-a4b0-4184-89d8-3ffd11177b33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9499"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skipgram.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mx6NU83WCaL1",
    "outputId": "f9e59a23-3f98-4465-b92c-6cf1253ee5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skipgram.get_weights()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwHlFJ4VCc7J",
    "outputId": "2b36fc66-f88f-4e44-883d-847a7e4234b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32527888, -0.12163258,  0.16216542,  0.04127095, -0.11305285,\n",
       "        0.19053659,  0.08194021,  0.0827537 , -0.09798235, -0.12230548,\n",
       "       -0.10925728, -0.4509574 ,  0.10556727, -0.06375656,  0.03762622,\n",
       "       -0.29934317, -0.11401577, -0.21341637,  0.15974396, -0.26582593,\n",
       "       -0.08370542, -0.22188632,  0.09298911,  0.12538494, -0.11680766,\n",
       "       -0.211973  , -0.05952676, -0.13551821, -0.23344664,  0.11647146,\n",
       "        0.577134  ,  0.10741807, -0.1729161 , -0.2584268 , -0.05339617,\n",
       "       -0.00989427, -0.12786208,  0.11358162,  0.36213025, -0.16353655,\n",
       "       -0.06297044,  0.2722588 ,  0.02155973,  0.32286486, -0.24523337,\n",
       "       -0.19401504, -0.03977433, -0.04972154, -0.3587838 ,  0.29570627,\n",
       "       -0.16750993, -0.17616794, -0.09405033, -0.14426138,  0.43670478,\n",
       "        0.18446957, -0.09198372, -0.14051612, -0.3323797 ,  0.02338192,\n",
       "        0.21787195,  0.5718953 ,  0.18932514,  0.11112643, -0.11459134,\n",
       "       -0.14072517, -0.36717772,  0.27305597,  0.24377222,  0.16949068,\n",
       "       -0.13279717,  0.38220346, -0.24855086,  0.08712644,  0.43760487,\n",
       "       -0.01436157,  0.4520941 ,  0.16934818, -0.07156061, -0.2384866 ,\n",
       "       -0.26229596,  0.1488423 ,  0.09520319,  0.05712694,  0.14772895,\n",
       "        0.16779572,  0.08776206, -0.08861139,  0.44105607, -0.29034212,\n",
       "       -0.08173452, -0.13712132,  0.11097154, -0.1899158 ,  0.27781978,\n",
       "       -0.1927428 ,  0.09678519,  0.17729713,  0.11113989, -0.15992746,\n",
       "        0.18673593, -0.09404584,  0.04331918,  0.42953178,  0.16301374,\n",
       "       -0.07732054,  0.06014225, -0.2733196 ,  0.15349191,  0.20191589,\n",
       "       -0.09310058,  0.06670728, -0.06785204, -0.11617914,  0.2728991 ,\n",
       "        0.19980985,  0.11675104, -0.11857912,  0.20100196,  0.03597452,\n",
       "       -0.18281843,  0.13813487,  0.17885908, -0.08832918,  0.20155233,\n",
       "        0.19454904,  0.05179322, -0.19458494, -0.18829417, -0.0106794 ,\n",
       "       -0.14968136, -0.20768557,  0.14463726,  0.2648777 , -0.18552199,\n",
       "        0.08893831,  0.07741255,  0.1649029 , -0.24588414,  0.33861285,\n",
       "       -0.14955847,  0.1806456 ,  0.0188357 , -0.28710192, -0.19516504,\n",
       "       -0.05227882, -0.15573584, -0.05482898,  0.18592618,  0.2432082 ,\n",
       "        0.05730905,  0.38879645, -0.37206352, -0.11824674, -0.01570346,\n",
       "       -0.19908613,  0.20183812,  0.18514729, -0.24327868, -0.05014203,\n",
       "        0.07461371,  0.20322439, -0.09592578, -0.06384765,  0.15097333,\n",
       "        0.2842425 , -0.01125864, -0.05262524, -0.20841333,  0.18776084,\n",
       "       -0.03802385,  0.04859041,  0.0359308 , -0.37226716, -0.03599911,\n",
       "        0.22999977,  0.26950938,  0.21129513,  0.17133643,  0.00598759,\n",
       "       -0.20905977,  0.25794014, -0.04607625, -0.19170749, -0.05243718,\n",
       "       -0.00422014, -0.18449727, -0.07869535,  0.00834407,  0.33769983,\n",
       "       -0.09018592, -0.23380525,  0.10233523,  0.09088876, -0.19929561,\n",
       "       -0.22401524,  0.11880612,  0.03629792, -0.00502246, -0.13507953,\n",
       "       -0.13224006,  0.33584505,  0.10159231, -0.0294094 ,  0.23179545,\n",
       "        0.28019214, -0.0920004 ,  0.15261543,  0.20394517, -0.03860423,\n",
       "       -0.05235856,  0.03414703,  0.10950235, -0.41248357,  0.28772977,\n",
       "        0.20317371,  0.24337727,  0.23271807, -0.2505529 , -0.3292984 ,\n",
       "        0.19450411,  0.08564607,  0.30240706, -0.03453447, -0.0461999 ,\n",
       "       -0.03993657, -0.1872721 , -0.01311483, -0.16839327,  0.22013277,\n",
       "       -0.24193166, -0.05365696,  0.2761376 , -0.23476239,  0.17048216,\n",
       "        0.09544214, -0.39211428,  0.30647278, -0.07175793, -0.08830334,\n",
       "        0.21628325, -0.12313652,  0.05132163,  0.05588764, -0.13916562,\n",
       "       -0.10077173,  0.03682519, -0.19434693, -0.23232521,  0.15199353,\n",
       "       -0.35446635,  0.07194125,  0.12537636,  0.06896745,  0.20493847,\n",
       "       -0.25505728,  0.56563646,  0.34984767,  0.05832923, -0.31676787,\n",
       "       -0.11607086, -0.2046676 , -0.17079054, -0.11756942,  0.06068256,\n",
       "       -0.38296482,  0.33464488,  0.11079439,  0.33683532, -0.18149877,\n",
       "       -0.20504439, -0.13533114, -0.28757262,  0.00976854, -0.19205002,\n",
       "        0.302365  , -0.12496157,  0.09129265, -0.14916767,  0.1782551 ,\n",
       "        0.51355946,  0.03358747, -0.10804403,  0.24071994,  0.32555255,\n",
       "       -0.019339  ,  0.15769777,  0.02204375, -0.06098796, -0.19265233,\n",
       "       -0.17100601,  0.02830504,  0.11727213, -0.01267455,  0.19385047,\n",
       "        0.0900377 ,  0.00370015, -0.18126906,  0.12671961, -0.10615522],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WndM_dgtBsB3"
   },
   "source": [
    "To get the word embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "stGNMknWCga3"
   },
   "outputs": [],
   "source": [
    "index = tokenizer.word_index['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQIeSU9YCqLk",
    "outputId": "717bbd68-0248-4615-ef62-a207427cbd8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2885331 ,  0.51821667, -0.17127907,  0.2747276 , -0.01620254,\n",
       "        0.498448  ,  0.26440337, -0.47260427,  0.10990763,  0.04294791,\n",
       "       -0.08642849, -0.11361936, -0.6033893 , -0.10924914,  0.1353534 ,\n",
       "        0.07647365, -0.0427232 , -0.17580122,  0.09824131, -0.14217344,\n",
       "        0.31400818, -0.05618232, -0.2700428 , -0.19324386,  0.17674293,\n",
       "        0.01983271, -0.08673499,  0.3545664 ,  0.36137933,  0.1838298 ,\n",
       "       -0.19554509, -0.17966843, -0.37718725, -0.23053116,  0.3574334 ,\n",
       "        0.2850941 ,  0.15157783, -0.22383724,  0.23521915,  0.41887844,\n",
       "       -0.0097496 , -0.09284983,  0.454733  ,  0.03409092,  0.58624476,\n",
       "        0.06892834, -0.16144466,  0.40544748, -0.59082067, -0.0590856 ,\n",
       "       -0.05896838,  0.14168249,  0.13438728,  0.03637302,  0.37622723,\n",
       "       -0.06925197,  0.33077374, -0.5664501 , -0.15090407, -0.22181164,\n",
       "        0.0279519 , -0.4537112 , -0.11181034, -0.39456737,  0.0290822 ,\n",
       "       -0.37076977, -0.21548012,  0.3339463 ,  0.03860397,  0.21568967,\n",
       "       -0.18674777, -0.25486398, -0.37671334,  0.01665547, -0.18412095,\n",
       "        0.49090743,  0.37606332,  0.24175826, -0.34241605, -0.24697414,\n",
       "        0.37688023, -0.21971676, -0.33748898,  0.08936689,  0.26958144,\n",
       "        0.36621997, -0.01029357, -0.01621155,  0.50273925,  0.08526746,\n",
       "        0.01571496, -0.04618322,  0.36401755,  0.4518768 , -0.07623944,\n",
       "       -0.06135445,  0.38780951, -0.30026066,  0.33326727, -0.16620567,\n",
       "        0.10801809,  0.22209848,  0.14301334,  0.47262493, -0.11350643,\n",
       "        0.16068152,  0.27193552, -0.05374585,  0.32835636, -0.4325078 ,\n",
       "       -0.12450357,  0.26799506,  0.0231158 , -0.22329012,  0.44610095,\n",
       "       -0.25573313, -0.07663698,  0.18279944, -0.2295295 ,  0.20435917,\n",
       "       -0.17457637, -0.4216095 , -0.2624266 , -0.14376023, -0.04066128,\n",
       "       -0.01268228,  0.18855059,  0.6847311 , -0.35924762,  0.1524174 ,\n",
       "        0.08690392, -0.48447227, -0.4894008 , -0.39609414, -0.5103763 ,\n",
       "       -0.13913672, -0.01816877, -0.04648366, -0.05665584,  0.1076192 ,\n",
       "        0.03780991,  0.52275854, -0.30814674, -0.32280526,  0.4420026 ,\n",
       "        0.06511264, -0.05936007,  0.12328977,  0.16018876,  0.5318042 ,\n",
       "       -0.08286726, -0.15238786,  0.06058429, -0.21433434,  0.5383733 ,\n",
       "        0.42554554, -0.11169598,  0.24989541, -0.1650487 ,  0.26995033,\n",
       "        0.43259755,  0.12486174,  0.2044706 ,  0.0487633 ,  0.5524618 ,\n",
       "       -0.1506415 , -0.20045511, -0.45550704,  0.08526024,  0.11440774,\n",
       "       -0.1096596 ,  0.03312365,  0.16025962,  0.2510215 ,  0.15874408,\n",
       "       -0.12816706,  0.10876545,  0.49621537,  0.13206205,  0.03252025,\n",
       "        0.17468238,  0.13103734,  0.22875646, -0.38299957, -0.03475861,\n",
       "       -0.10905308, -0.3277872 , -0.20718841, -0.04159884, -0.01278363,\n",
       "       -0.34041765, -0.22577117,  0.0511258 ,  0.11716004,  0.20222852,\n",
       "       -0.00643431, -0.4128125 , -0.13421933,  0.3219913 , -0.35643724,\n",
       "       -0.00856499,  0.35798505,  0.01613003, -0.27561095, -0.21503608,\n",
       "        0.424233  ,  0.19960457,  0.34331974, -0.043617  ,  0.4288516 ,\n",
       "       -0.13397336,  0.06040096, -0.1202791 ,  0.19919766, -0.4198036 ,\n",
       "       -0.1053909 , -0.14276585,  0.27717412,  0.35438734,  0.21717244,\n",
       "       -0.05058364, -0.09628209, -0.41638127,  0.20619424, -0.06721094,\n",
       "       -0.24679196, -0.3108144 , -0.3440315 ,  0.18996774,  0.29174122,\n",
       "       -0.1345671 , -0.18243542, -0.2699581 ,  0.7779461 , -0.01818737,\n",
       "       -0.18096884,  0.38850793, -0.01695647, -0.2436892 ,  0.26829538,\n",
       "       -0.03643704,  0.19988929,  0.23161203, -0.06739516, -0.26155624,\n",
       "        0.0936939 ,  0.15916327,  0.04705772,  0.16946615, -0.14733762,\n",
       "        0.07916385,  0.41009715,  0.05611912, -0.06094585, -0.2986191 ,\n",
       "       -0.01510758,  0.31679663,  0.01660147, -0.1437927 ,  0.0572046 ,\n",
       "       -0.31294563,  0.02597244, -0.10669519, -0.14645763, -0.2138996 ,\n",
       "        0.03148826, -0.09018771, -0.07667257,  0.32193837, -0.37466806,\n",
       "        0.24731274, -0.37341517, -0.25770637, -0.18388736,  0.1667427 ,\n",
       "       -0.2797105 ,  0.26061934,  0.10804325,  0.42350972,  0.04825311,\n",
       "       -0.16483282, -0.4531881 , -0.16430527, -0.06841018,  0.7080415 ,\n",
       "       -0.098997  , -0.25909847,  0.32189623,  0.14667904,  0.20209324,\n",
       "        0.56772864, -0.5170064 ,  0.17866126,  0.22126706,  0.43081915,\n",
       "        0.02582485, -0.20447072,  0.06738249, -0.27562964, -0.00106696],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram.get_weights()[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest words to 'king':\n",
      "fisher: 0.4934\n",
      "supreme: 0.4713\n",
      "confirms: 0.4438\n",
      "teen: 0.4421\n",
      "mervyn: 0.4368\n",
      "adaptation: 0.4322\n",
      "abdullah: 0.4096\n",
      "zone: 0.4055\n",
      "adventures: 0.3999\n",
      "tote: 0.3862\n"
     ]
    }
   ],
   "source": [
    "# Load the word vectors\n",
    "word_vectors_skipGram = loadFile(\"vectors_skipgram_300.txt\")\n",
    "\n",
    "# Find nearest words to the target word\n",
    "target_word = \"king\"\n",
    "nearest_words_skipGram = nearestWords(target_word, word_vectors_skipGram)\n",
    "\n",
    "print(f\"Nearest words to '{target_word}':\")\n",
    "for word, similarity in nearest_words_skipGram:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVkTnQHpBC9G"
   },
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mjFSAz4xM0Zs"
   },
   "outputs": [],
   "source": [
    "# The function returns two arrays: all_in, which contains the context words, \n",
    "# and all_out, which contains the corresponding one-hot encoded target words.\n",
    "\n",
    "def generate_data_cbow(corpus, window_size, V):\n",
    "    all_in = []\n",
    "    all_out = []\n",
    "\n",
    "    # Iterate over all sentences\n",
    "    for sentence in corpus:\n",
    "        L = len(sentence)\n",
    "        for index, word in enumerate(sentence):\n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "\n",
    "            # Empty list which will store the context words\n",
    "            context_words = []\n",
    "            for i in range(start, end):\n",
    "                # Skip the 'same' word\n",
    "                if i != index:\n",
    "                    # Add a word as a context word if it is within the window size\n",
    "                    if 0 <= i < L:\n",
    "                        context_words.append(sentence[i])\n",
    "                    else:\n",
    "                        # Pad with zero if there are no words\n",
    "                        context_words.append(0)\n",
    "            # Append the list with context words\n",
    "            all_in.append(context_words)\n",
    "\n",
    "            # Add one-hot encoding of the target word\n",
    "            all_out.append(to_categorical(word, V))\n",
    "\n",
    "    return (np.array(all_in), np.array(all_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "an4kfPrHM4BV",
    "outputId": "c41af6ea-3637-48cc-b90e-e09bbcf8fd18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 656 ms\n",
      "Wall time: 11.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((41552, 4), (41552, 9499))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create the training data\n",
    "X_cbow, y_cbow = generate_data_cbow(corpus_sequences, window_size, V)\n",
    "X_cbow.shape, y_cbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0  298 2035]\n",
      " [   0  147 2035  701]\n",
      " [ 147  298  701   66]\n",
      " [ 298 2035   66  777]\n",
      " [2035  701  777 1430]\n",
      " [ 701   66 1430 4878]\n",
      " [  66  777 4878 2524]\n",
      " [ 777 1430 2524 4879]\n",
      " [1430 4878 4879  299]\n",
      " [4878 2524  299  322]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_cbow[:10])\n",
    "print(y_cbow[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJBnZ-lAM7o0",
    "outputId": "1eb5dcbe-790d-4b87-8b4c-a1b12e7a3e63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Snape\\anaconda3\\envs\\torch\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 264 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create the CBOW architecture\n",
    "cbow_models = []\n",
    "dim = 300\n",
    "cbow = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "cbow.add(Embedding(input_dim=V,\n",
    "                    output_dim=dim,\n",
    "                    input_length=window_size*2, # Note that we now have 2L words for each input entry\n",
    "                    embeddings_initializer='glorot_uniform'))\n",
    "\n",
    "cbow.add(Lambda(lambda x: tf.reduce_mean(x, axis=1), output_shape=(dim, )))\n",
    "\n",
    "cbow.add(Dense(V, activation='softmax', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "cbow.compile(optimizer=keras.optimizers.Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "cbow.summary()\n",
    "print(\"\")\n",
    "cbow_models.append(cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZywPe5gyM-O6",
    "outputId": "7170089a-0460-4b6e-d34a-a3a6db2d9bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - accuracy: 0.0132 - loss: 8.8946\n",
      "Epoch 2/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 71ms/step - accuracy: 0.0164 - loss: 8.1925\n",
      "Epoch 3/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 94ms/step - accuracy: 0.0260 - loss: 7.9483\n",
      "Epoch 4/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 86ms/step - accuracy: 0.0418 - loss: 7.6224\n",
      "Epoch 5/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.0684 - loss: 7.1334\n",
      "Epoch 6/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.0996 - loss: 6.4569\n",
      "Epoch 7/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.1451 - loss: 5.6724\n",
      "Epoch 8/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.2075 - loss: 4.8524\n",
      "Epoch 9/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 58ms/step - accuracy: 0.2832 - loss: 4.0664\n",
      "Epoch 10/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 82ms/step - accuracy: 0.3710 - loss: 3.3602\n",
      "Epoch 11/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 83ms/step - accuracy: 0.4711 - loss: 2.7374\n",
      "Epoch 12/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 62ms/step - accuracy: 0.5711 - loss: 2.2171\n",
      "Epoch 13/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.6679 - loss: 1.7796\n",
      "Epoch 14/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7610 - loss: 1.3894\n",
      "Epoch 15/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.8253 - loss: 1.1041\n",
      "Epoch 16/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 82ms/step - accuracy: 0.8744 - loss: 0.8639\n",
      "Epoch 17/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 81ms/step - accuracy: 0.9119 - loss: 0.6702\n",
      "Epoch 18/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 79ms/step - accuracy: 0.9389 - loss: 0.5192\n",
      "Epoch 19/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 82ms/step - accuracy: 0.9549 - loss: 0.4077\n",
      "Epoch 20/20\n",
      "\u001b[1m650/650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 88ms/step - accuracy: 0.9659 - loss: 0.3222\n",
      "\n",
      "CPU times: total: 36min 22s\n",
      "Wall time: 13min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train CBOW model\n",
    "for cbow in cbow_models:\n",
    "    cbow.fit(X_cbow, y_cbow, batch_size=64, epochs=20, verbose=1)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "tIzwSyBRNC-V"
   },
   "outputs": [],
   "source": [
    "for cbow in cbow_models:\n",
    "\n",
    "    weights = cbow.get_weights()\n",
    "\n",
    "    # Get the embedding matrix\n",
    "    embedding = weights[0]\n",
    "\n",
    "    # Get word embeddings for each word in the vocabulary, write to file\n",
    "    f = open(f'vectors_cbow_{len(embedding[0])}.txt', 'w')\n",
    "\n",
    "    # Create columns for the words and the values in the matrix, makes it easier to read as dataframe\n",
    "    columns = [\"word\"] + [f\"value_{i+1}\" for i in range(embedding.shape[1])]\n",
    "\n",
    "    # Start writing to the file, start with the column names\n",
    "    f.write(\" \".join(columns))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        f.write(word)\n",
    "        f.write(\" \")\n",
    "        f.write(\" \".join(map(str, list(embedding[i,:]))))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest words to 'king':\n",
      "fisher: 0.3907\n",
      "oscar: 0.3745\n",
      "nominee: 0.3631\n",
      "supreme: 0.3285\n",
      "mervyn: 0.3263\n",
      "teen: 0.3255\n",
      "confirms: 0.3195\n",
      "oneman: 0.3066\n",
      "tote: 0.2919\n",
      "midbedfordshire: 0.2907\n"
     ]
    }
   ],
   "source": [
    "# Load the word vectors\n",
    "word_vectors_cbow = loadFile(\"vectors_cbow_300.txt\")\n",
    "\n",
    "# Find nearest words to the target word\n",
    "target_word = \"king\"\n",
    "nearest_words_cbow = nearestWords(target_word, word_vectors_cbow)\n",
    "\n",
    "print(f\"Nearest words to '{target_word}':\")\n",
    "for word, similarity in nearest_words_cbow:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0TRjJt_BzEl"
   },
   "source": [
    "To get the word embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hD90GjaOB14b",
    "outputId": "af0dfd63-ecb2-4b3b-f558-d4f9ab4e8b1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9498, 9498)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skipgram_word_emd),len(cbow_word_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uAu2hbWgDh8H",
    "outputId": "5c04dc9d-6349-4c20-9ceb-34252ee51371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04811318]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([skipgram_word_emd['king']], [cbow_word_emd['king']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbCqkmPZFxwk",
    "outputId": "18c0ed2a-4069-4ccd-eceb-b08fb80c2c3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0732749]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([skipgram_word_emd['queen']], [cbow_word_emd['queen']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WqqC9hlDtgs",
    "outputId": "69c5c9fc-edcb-495f-e887-32ed151d0477"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15288118]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([skipgram_word_emd['king']], [skipgram_word_emd['queen']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dn76dASUD4FT",
    "outputId": "44d86057-a81e-4a40-d5b0-f420f4b01810"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04786081]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([cbow_word_emd['king']], [cbow_word_emd['queen']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file):\n",
    "    print(\"Loading GloVe vectors...\")\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        word_embeddings = {}\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            word_embeddings[word] = coefs\n",
    "    print(f\"Total words in GloVe: {len(word_embeddings)}\")\n",
    "    return word_embeddings\n",
    "\n",
    "def get_word_vector(word, embeddings):\n",
    "    print(f\"Total words in GloVe: {len(embeddings)}\")\n",
    "    return embeddings.get(word, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe vectors...\n",
      "Total words in GloVe: 400001\n",
      "Total words in GloVe: 400001\n",
      "Vector for 'example': [ 0.51564    0.56912   -0.19759    0.0080456  0.41697    0.59502\n",
      " -0.053312  -0.83222   -0.21715    0.31045    0.09352    0.35323\n",
      "  0.28151   -0.35308    0.23496    0.04429    0.017109   0.0063749\n",
      " -0.01662   -0.69576    0.019819  -0.52746   -0.14011    0.21962\n",
      "  0.13692   -1.2683    -0.89416   -0.1831     0.23343   -0.058254\n",
      "  3.2481    -0.48794   -0.01207   -0.81645    0.21182   -0.17837\n",
      " -0.02874    0.099358  -0.14944    0.2601     0.18919    0.15022\n",
      "  0.18278    0.50052   -0.025532   0.24671    0.10596    0.13612\n",
      "  0.0090427  0.39962  ]\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe vectors\n",
    "glove_file = 'pre-train\\glove.6B.50d.txt'\n",
    "word_embeddings = load_glove_model(glove_file)\n",
    "\n",
    "# Get vector for a specific word\n",
    "word = 'example'\n",
    "vector = get_word_vector(word, word_embeddings)\n",
    "print(f\"Vector for '{word}': {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest words to 'king':\n",
      "prince: 0.8236\n",
      "queen: 0.7839\n",
      "ii: 0.7746\n",
      "emperor: 0.7736\n",
      "son: 0.7667\n",
      "uncle: 0.7627\n",
      "kingdom: 0.7542\n",
      "throne: 0.7540\n",
      "brother: 0.7492\n",
      "ruler: 0.7434\n"
     ]
    }
   ],
   "source": [
    "# Load the word vectors\n",
    "word_vectors = loadFile(\"pre-train/glove.6B.50d.txt\")\n",
    "\n",
    "# Find nearest words to the target word\n",
    "target_word = \"king\"\n",
    "nearest_words = nearestWords(target_word, word_vectors)\n",
    "\n",
    "print(f\"Nearest words to '{target_word}':\")\n",
    "for word, similarity in nearest_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save corpus_cleaned to data.txt\n",
    "with open('data.txt', 'w') as f:\n",
    "    for sentence in corpus_cleaned:\n",
    "        f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "# Skipgram model :\n",
    "model_skipgram = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
    "model_cbow = fasttext.train_unsupervised('data.txt', model='cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035\n",
      "['</s>', 'said', 'mr', 'would', 'us']\n"
     ]
    }
   ],
   "source": [
    "print(len(model_skipgram.words))   # list of words in dictionary\n",
    "print(model_skipgram.words[:5])   # list of words in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035\n",
      "['</s>', 'said', 'mr', 'would', 'us']\n"
     ]
    }
   ],
   "source": [
    "print(len(model_cbow.words))   # list of words in dictionary\n",
    "print(model_cbow.words[:5])   # list of words in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12809202 -0.06241307 -0.5373109  -0.07898965 -0.17456539 -0.01499808\n",
      " -0.04510237 -0.12413687  0.11719195  0.21051577 -0.06993252  0.31800944\n",
      "  0.40157363  0.01828186 -0.0802449   0.01835513  0.18282847 -0.03645166\n",
      "  0.23834257 -0.17484272 -0.24756224  0.03784261 -0.06942379  0.08270446\n",
      "  0.19014034 -0.0667494   0.0468164  -0.05474981 -0.12270254  0.01528442\n",
      "  0.19886202 -0.01764523 -0.23059776 -0.06587476  0.01497575  0.25735182\n",
      "  0.05171872 -0.10021929 -0.4172717  -0.09823438  0.24158943  0.1446235\n",
      "  0.11621234 -0.16488473  0.13652135 -0.09762552 -0.18743338  0.02908867\n",
      " -0.02417079 -0.07592172 -0.10909104  0.3557273   0.04537655  0.12654407\n",
      "  0.05257778 -0.29432368  0.07294812  0.07641889  0.01687525 -0.08029394\n",
      " -0.39478365  0.09077107  0.17239797  0.12128054 -0.14266208 -0.23614943\n",
      " -0.11491174  0.05627097  0.3311356  -0.00069061  0.03242769 -0.01866153\n",
      " -0.03778111  0.34889865 -0.06612207 -0.05382381  0.37602648  0.1790597\n",
      "  0.06545603 -0.20696251  0.08220818  0.05382765  0.03833375  0.03197234\n",
      " -0.14231847 -0.12483088 -0.03718355  0.01566092 -0.01363631 -0.05708751\n",
      "  0.2628723  -0.17091267  0.06685822 -0.21956696  0.15644097 -0.01081243\n",
      "  0.09619805  0.47561157 -0.5107155  -0.26453447]\n"
     ]
    }
   ],
   "source": [
    "print(model_skipgram['king']) # get the vector of the word 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0723238  -0.16722362 -0.9487884  -0.0874353  -0.5591405  -0.22758369\n",
      "  0.07761426 -0.5468157  -0.09940009  0.14080796 -0.22445373  0.60899127\n",
      "  0.76282626 -0.25866792 -0.25519374  0.03502591  0.54408073 -0.16598192\n",
      "  0.50998914 -0.23766646 -0.70327634 -0.13285232  0.12252723 -0.02771314\n",
      "  0.45805734  0.06522045  0.28230363 -0.18451302 -0.1954119  -0.4568035\n",
      "  0.6430413  -0.30580673 -0.05302715 -0.3639861   0.35608926  0.5884223\n",
      "  0.24000968  0.06901143 -1.0804046  -0.15920348  0.1401544  -0.10084464\n",
      " -0.11501204 -0.23083207  0.34574363 -0.04043501 -0.31826505  0.08892837\n",
      " -0.06327876 -0.23940556  0.02021915  0.59051436  0.15839747  0.53370696\n",
      "  0.19323735 -0.88662004  0.12882155  0.21580972 -0.16266775  0.05295403\n",
      " -0.69453114  0.144061    0.24484323 -0.01265344 -0.22165284 -0.74223036\n",
      " -0.18441418 -0.03459466  0.42404076 -0.32759324  0.60522413 -0.30698386\n",
      "  0.10658323  0.64038175  0.06307451 -0.04499795  0.66419554  0.34348848\n",
      "  0.4633894  -0.28266683  0.4564947  -0.12463069 -0.24352328  0.52992094\n",
      " -0.40644175 -0.18853039 -0.22243871 -0.10464014 -0.03160137  0.20877457\n",
      "  0.4017303  -0.43547758 -0.26806122 -0.25034967  0.3097125   0.19849882\n",
      "  0.1342541   1.2082961  -0.9407504  -0.859645  ]\n"
     ]
    }
   ],
   "source": [
    "print(model_cbow['king']) # get the vector of the word 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9998900294303894, 'evening'),\n",
       " (0.9998785853385925, 'planning'),\n",
       " (0.9998743534088135, 'blogging'),\n",
       " (0.9998684525489807, 'helping'),\n",
       " (0.9998652338981628, 'talking'),\n",
       " (0.9998651146888733, 'turning'),\n",
       " (0.9998628497123718, 'watching'),\n",
       " (0.9998627305030823, 'running'),\n",
       " (0.9998591542243958, 'downing'),\n",
       " (0.9998563528060913, 'encouraging')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram.get_nearest_neighbors('kings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.999973714351654, 'king'),\n",
       " (0.9999666213989258, 'evening'),\n",
       " (0.9999646544456482, 'going'),\n",
       " (0.9999641180038452, 'running'),\n",
       " (0.9999632835388184, 'planning'),\n",
       " (0.9999628067016602, 'making'),\n",
       " (0.999962568283081, 'starting'),\n",
       " (0.9999619722366333, 'winning'),\n",
       " (0.9999617338180542, 'writing'),\n",
       " (0.9999616742134094, 'starring')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow.get_nearest_neighbors('kings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save corpus_cleaned to data.txt\n",
    "with open('pre-train/glove.6B.50d.txt', 'w') as f:\n",
    "    for sentence in corpus_cleaned:\n",
    "        f.write(sentence + '\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
